{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ADDIITIONAL FILES 1 - 22**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nahila.Chowdhury\\AppData\\Local\\Temp\\ipykernel_26400\\4125756671.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import os\n",
    "from pandas.api.types import is_object_dtype, is_numeric_dtype, is_bool_dtype, is_string_dtype, is_float_dtype\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "import openpyxl\n",
    "import os.path\n",
    "from openpyxl.styles import PatternFill\n",
    "import traceback\n",
    "from openpyxl import Workbook\n",
    "import datetime\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "green_fill = PatternFill(start_color='72C931', end_color='72C931', fill_type='solid')\n",
    "red_fill = PatternFill(start_color='FABF8F', end_color='FABF8F', fill_type='solid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File location and names\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_output_path = r\"C:\\Users\\Nahila.Chowdhury\\OneDrive - OFWAT\\Data\\Business Plan Tables\\August 2024 BPT Submission\\error\\proteus error\\Additional tables\\\\\"\n",
    "input_files = r\"C:\\Users\\Nahila.Chowdhury\\OneDrive - OFWAT\\Data\\Business Plan Tables\\August 2024 BPT Submission\\3_Files error fixing WORKING\\Additional Tables\"\n",
    "v7_bpt = r\"C:\\Users\\Nahila.Chowdhury\\OneDrive - OFWAT\\Data\\Business Plan Tables\\August 2024 BPT Submission\\1_Files as submitted\\Additional Tables\\Copy of PR24 NEW BPDT's for Post DD collection - Master.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(dict_of_sheets, original_dict_of_sheets, excel_error_log_name):\n",
    "    firstsheet = excel_error_log_name['Intro']\n",
    "    try:\n",
    "        for key, value in dict_of_sheets.items():\n",
    "            if value[1] == \"fOut_\":\n",
    "                if fOut_headers_consistency(key, value[0], excel_error_log_name):  # Rule  1\n",
    "                    regex_boncode(key,value[0],excel_error_log_name) #Rule 2\n",
    "                    #check_suffix(key,value[0],excel_error_log_name) #Rule 3\n",
    "                    check_data_type(key,value[0],excel_error_log_name) #Rule 4\n",
    "                    check_ref(key,value[0],excel_error_log_name) #Rule 5\n",
    "                    user_text_input(key,value[0],excel_error_log_name) #Rule 6\n",
    "                    boncode_Consistency(key,value[0],original_dict_of_sheets[key][0],excel_error_log_name) #Rule 7\n",
    "                    boncode_Uniqueness(key, value[0],excel_error_log_name) #Rule 8\n",
    "                    user_numerical_input(key,value[0],excel_error_log_name) #Rule 9\n",
    "                    percentage_range(key,value[0],excel_error_log_name) #Rule 10\n",
    "    except ValueError:\n",
    "        firstsheet['B6'].value = f\"{firstsheet['B6'].value} {ValueError}\"\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Import Company excel file\n",
    "def import_data(file_location, excel_error_log_name):\n",
    "    firstsheet = excel_error_log_name['Intro']\n",
    "    try:\n",
    "        xl1 = pd.ExcelFile(file_location)  # Define the excel file\n",
    "        worksheets = xl1.sheet_names  # Get the list of worksheets in the file\n",
    "        found_dictionary, found_f_outputs = (False, False)\n",
    "        dict_of_sheets = {}\n",
    "        for sheet in worksheets:  # iterate through the sheets in the file\n",
    "            if sheet.startswith(\"Dict_\"):  # ...if the worksheet starts with the text \"Dict_\" then...\n",
    "                found_dictionary = True\n",
    "                dict_of_sheets[sheet] = (pd.read_excel(xl1, sheet_name=sheet, skiprows=[0, 2]), \"Dict_\")\n",
    "            if sheet.startswith(\"fOut_\"):  # ...if the workseet starts with the text \"fOut\" then...\n",
    "                found_f_outputs = True\n",
    "                dict_of_sheets[sheet] = (pd.read_excel(xl1, sheet_name=sheet, skiprows=[0, 2]), \"fOut_\")\n",
    "        if not found_f_outputs:\n",
    "            firstsheet['B6'].value = f\"{firstsheet['B6'].value} Error message: A worksheet starting with 'fOut_' (an F_Outputs sheet) was not found in worksheets, Proteus has failed to run\"\n",
    "            firstsheet['B6'].fill = red_fill\n",
    "    except ValueError:\n",
    "        firstsheet['B6'].value = f\"{firstsheet['B6'].value} {ValueError}\"\n",
    "        firstsheet['B6'].fill = red_fill\n",
    "        pass\n",
    "    return dict_of_sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Import original excel file : V7\n",
    "def import_original_data(original_file_location, excel_error_log_name):\n",
    "    firstsheet = excel_error_log_name['Intro']\n",
    "    try:\n",
    "        xl1 = pd.ExcelFile(original_file_location)  # Define the excel file\n",
    "        worksheets = xl1.sheet_names  # Get the list of worksheets in the file\n",
    "        original_dict_of_sheets = {}\n",
    "        for sheet in worksheets:  # iterate through the sheets in the file\n",
    "            if sheet.startswith(\"Dict_\"):  # ...if the workseet starts with the text \"Dict_\" then...\n",
    "                original_dict_of_sheets[sheet] = (pd.read_excel(xl1, sheet_name=sheet, skiprows=[0, 2]), \"Dict_\")\n",
    "            if sheet.startswith(\"fOut_\"):  # ...if the workseet starts with the text \"fOut\" then...\n",
    "                excel_error_log_name.create_sheet(title=sheet[5:] + ' Output')  # creating the sheets which will house the tables of outputs\n",
    "                original_dict_of_sheets[sheet] = (pd.read_excel(xl1, sheet_name=sheet, skiprows=[0, 2]), \"fOut_\")\n",
    "    except ValueError:\n",
    "        firstsheet['B6'].value = f\"{firstsheet['B6'].value} {ValueError}\"\n",
    "        firstsheet['B6'].fill = red_fill\n",
    "        pass\n",
    "    return original_dict_of_sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def timestamp_error_log(excel_error_log_name):\n",
    "    firstsheet = excel_error_log_name['Intro']\n",
    "    try:\n",
    "        # storing current date and time\n",
    "        current_date_time = datetime.datetime.now().strftime(\"%d.%b %Y %H:%M:%S\")\n",
    "        firstsheet['B4'].value = f\"This file was created at: {current_date_time}\"\n",
    "    except ValueError:\n",
    "        firstsheet['B6'].value = f\"{firstsheet['B6'].value} {ValueError}\"\n",
    "        firstsheet['B6'].fill = red_fill\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fOut_headers_consistency(sheet_name, df, excel_error_log_name):\n",
    "    ## ---------------------------------------------------------------------\n",
    "    ## *Headers* in spesific order and value. Headers are case insensitive\n",
    "    ## ----------------------------------------------------------------------\n",
    "    firstsheet = excel_error_log_name['Intro']\n",
    "    try:\n",
    "        outputsheet = excel_error_log_name[sheet_name[5:] + ' Output'] #defining which sheet the output needs to go into\n",
    "        outputsheet['B3'].value = 'Data Validation Rule 1'\n",
    "        outputsheet['C3'].value = \"\"\n",
    "\n",
    "        dictionary_errors_column_headers = {\n",
    "            'Acronym': (df.columns[0],\n",
    "                        \"Error message: 'Acronym' column name is not correct, please note name is case sensitive\"),\n",
    "            'Reference': (df.columns[1],\n",
    "                          \"Error message: 'Reference' column name is not correct, please note name is case sensitive\"),\n",
    "            'Item description': (df.columns[2],\n",
    "                                 \"Error message: 'Item description' column name is not correct, please note name is case sensitive\"),\n",
    "            'Unit': (\n",
    "            df.columns[3], \"Error message: 'Unit' column name is not correct, please note name is case sensitive\"),\n",
    "            'Model': (\n",
    "            df.columns[4], \"Error message: 'Model' column name is not correct, please note name is case sensitive\"),\n",
    "        }\n",
    "\n",
    "        error_counter = 0\n",
    "        for key, value in dictionary_errors_column_headers.items():\n",
    "            if key == value[0]:\n",
    "                pass\n",
    "            else:\n",
    "                error_counter += 1\n",
    "                outputsheet['C3'].value = f\"{outputsheet['C3'].value} {value[1]}\"\n",
    "                outputsheet['C3'].fill = red_fill\n",
    "        if error_counter == 0:\n",
    "            outputsheet['C3'].value = \"Success, No Errors detected!\"\n",
    "            outputsheet['C3'].fill = green_fill\n",
    "            return True\n",
    "        outputsheet['C3'].value = f\"{outputsheet['C3'].value} Please correct the header's names for this Excel Sheet: {sheet_name}, before data validation proceeds!\"\n",
    "        outputsheet['C3'].fill = red_fill\n",
    "        return False\n",
    "    except ValueError:\n",
    "        firstsheet['B6'].value = f\"{firstsheet['B6'].value} {ValueError}\"\n",
    "        firstsheet['B6'].fill = red_fill\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def regex_boncode(sheet_name,df,excel_error_log_name):\n",
    "##-------------------------------------------------------------------------------------------------------\n",
    "##Boncode find pattern using *Regex*. Reference (BON code) should consist of the following in sequence:\n",
    "##An upper case letter. Zero or more upper case letters or underscores.\n",
    "## At least one digit. Zero or more number upper case letters, underscores, or digits.\n",
    "##No lower case letters. Boncodes must not contain \"-\" character.\n",
    "##Note \"str.fullmatch\" doesn't work due to older python vesrion installed\n",
    "##-------------------------------------------------------------------------------------------------------\n",
    "    firstsheet = excel_error_log_name['Intro']\n",
    "    try:\n",
    "        outputsheet = excel_error_log_name[sheet_name[5:] + ' Output']  # defining which sheet the output needs to go into\n",
    "        outputsheet['B4'].value = 'Data Validation Rule 2'\n",
    "        outputsheet['C4'].value = \"\"\n",
    "        index=3 #index for showing cell position\n",
    "        regex = r'^([A-Z][A-Z_]*[0-9]+[A-Z0-9_]*)$'\n",
    "        regex_pattern = re.compile(regex)\n",
    "        error_counter=0\n",
    "        for item in df['Reference']:\n",
    "            index+=1\n",
    "            if pd.isna(item):\n",
    "                error_counter+=1\n",
    "                outputsheet['C4'].value = f\"{outputsheet['C4'].value} Error in Row {index}: 'Reference': {item}, 'Reference' is a mandatory field and cannot have empty values \\n\"\n",
    "                outputsheet['C4'].fill = red_fill\n",
    "                break\n",
    "            if bool(regex_pattern.match(item))==False:\n",
    "                error_counter+=1\n",
    "                outputsheet['C4'].value = f\"{outputsheet['C4'].value} Error in Row {index}: 'Reference': {item} doesn't match the regular expression \\n\"\n",
    "                outputsheet['C4'].fill = red_fill\n",
    "        if error_counter==0:\n",
    "            outputsheet['C4'].value = \"Success, No Errors detected!\"\n",
    "            outputsheet['C4'].fill = green_fill\n",
    "    except ValueError:\n",
    "        firstsheet['B6'].value = f\"{firstsheet['B6'].value} {ValueError} \\n\"\n",
    "        firstsheet['B6'].fill = red_fill\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_suffix(sheet_name, df, excel_error_log_name):\n",
    "    ## ---------------------------------------\n",
    "    ## Checking *suffix _PR24* on Boncodes\n",
    "    ## ---------------------------------------\n",
    "    firstsheet = excel_error_log_name['Intro']\n",
    "    try:\n",
    "        outputsheet = excel_error_log_name[sheet_name[5:] + ' Output']  # defining which sheet the output needs to go into\n",
    "        outputsheet['B5'].value = 'Data Validation Rule 3'\n",
    "        outputsheet['C5'].value = \"\"\n",
    "        index = 3  # index for showing row position\n",
    "        suffix = \"_PR24\"\n",
    "        error_counter = 0\n",
    "\n",
    "        for item in df['Reference']:\n",
    "            index += 1\n",
    "            if pd.notna(item):\n",
    "                if item.endswith(suffix):\n",
    "                    pass\n",
    "                else:\n",
    "                    error_counter += 1\n",
    "                    outputsheet['C5'].value = f\"{outputsheet['C5'].value} Error in Row {index}: Reference: {item} does not has a suffix _PR24\\n\"\n",
    "                    outputsheet['C5'].fill = red_fill\n",
    "        if error_counter == 0:\n",
    "            outputsheet['C5'].value =\"Success, No Errors detected!\"\n",
    "            outputsheet['C5'].fill = green_fill\n",
    "    except ValueError:\n",
    "        firstsheet['B6'].value = f\"{firstsheet['B6'].value} {ValueError} \\n\"\n",
    "        firstsheet['B6'].fill = red_fill\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_data_type(sheet_name, df, excel_error_log_name):\n",
    "    ## ------------------------------------------------------------------------------------------\n",
    "    ##6. *Data Type Checking*. This verifies that the entered data has the appropriate data type.\n",
    "    ## ------------------------------------------------------------------------------------------\n",
    "    # Unit: Unit must be less than 21 characters.\n",
    "    # Description: Description must be less than 230 characters.\n",
    "    regex_columns = r'^([0-9]{4}-[0-9]{2})$'\n",
    "    regex_pattern = re.compile(regex_columns)\n",
    "    firstsheet = excel_error_log_name['Intro']\n",
    "    try:\n",
    "        outputsheet = excel_error_log_name[sheet_name[5:] + ' Output']  # defining which sheet the output needs to go into\n",
    "        outputsheet['B6'].value = 'Data Validation Rule 4'\n",
    "        outputsheet['C6'].value = \"\"\n",
    "        index = 3  # index for showing row position\n",
    "        error_counter = 0\n",
    "        unit_length = 21\n",
    "        description_length = 230\n",
    "\n",
    "        for item1, item2, item3 in zip(df['Unit'], df['Reference'],df['Item description']):\n",
    "            index += 1\n",
    "            if type(item1) == int:\n",
    "                error_counter += 1\n",
    "                outputsheet['C6'].value = f\"{outputsheet['C6'].value} Error in Row {index}: Reference: {item2}: Unit must not be a number \\n\"\n",
    "                outputsheet['C6'].fill = red_fill\n",
    "            elif pd.notna(item1):\n",
    "                if len(item1) > unit_length:\n",
    "                    error_counter += 1\n",
    "                    outputsheet['C6'].value = f\"{outputsheet['C6'].value} Error in Row {index}: Reference: {item2}: Unit must be <={unit_length} characters \\n\"\n",
    "                    outputsheet['C6'].fill = red_fill\n",
    "            elif pd.notna(item3):\n",
    "                if len(item3) > description_length:\n",
    "                    error_counter += 1\n",
    "                    outputsheet['C6'].value = f\"{outputsheet['C6'].value} Error in Row {index}: Reference: {item2}: Description must be <={description_length} characters \\n\"\n",
    "                    outputsheet['C6'].fill = red_fill\n",
    "        index = 3\n",
    "        for i, row in df.iterrows():\n",
    "            index += 1\n",
    "            for key in row.keys():\n",
    "                if bool(regex_pattern.match(key)) or key.lower() == 'constant':\n",
    "                    if len(str(row[key])) > description_length:\n",
    "                        error_counter +=1\n",
    "                        outputsheet['C6'].value = f\"{outputsheet['C6'].value}Error in Row: {index}, Reference: {df.loc[i, 'Reference']},Column: {key}, Value: {row[key]}- this value is over 230 characters.\\n\\n\"\n",
    "                        outputsheet['C6'].fill = red_fill\n",
    "        if error_counter == 0:\n",
    "            outputsheet['C6'].value = \"Success, No Errors detected!\"\n",
    "            outputsheet['C6'].fill = green_fill\n",
    "    except ValueError:\n",
    "        firstsheet['B6'].value = f\"{firstsheet['B6'].value} {ValueError} \\n\"\n",
    "        firstsheet['B6'].fill = red_fill\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_ref(sheet_name, df, excel_error_log_name):\n",
    "    # REF! error\n",
    "    firstsheet = excel_error_log_name['Intro']\n",
    "    regex_columns = r'^([0-9]{4}-[0-9]{2})$'\n",
    "    regex_pattern = re.compile(regex_columns)\n",
    "    \n",
    "    try:\n",
    "        outputsheet = excel_error_log_name[sheet_name[5:] + ' Output']  # defining which sheet the output needs to go into\n",
    "        outputsheet['B7'].value = 'Data Validation Rule 5'\n",
    "        outputsheet['C7'].value = \"\"\n",
    "        index = 3\n",
    "        error_counter = 0\n",
    "\n",
    "        for i, row in df.iterrows():\n",
    "            index += 1\n",
    "            if row['Model'] and pd.isna(row['Reference']) and pd.isna(row['Unit']):\n",
    "                error_counter += 1\n",
    "                outputsheet['C7'].value = f\"{outputsheet['C7'].value} Error in Row: {index},\" \\\n",
    "                    \"This likely contains a reference error, please check \\n\"\n",
    "                outputsheet['C7'].fill = red_fill\n",
    "        if error_counter == 0:\n",
    "            outputsheet['C7'].value = \"Success, No Errors detected!\"\n",
    "            outputsheet['C7'].fill = green_fill\n",
    "    except ValueError:\n",
    "        firstsheet['B6'].value = f\"{firstsheet['B6'].value} {str(ValueError)} \\n\"\n",
    "        firstsheet['B6'].fill = red_fill\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def boncode_Uniqueness(sheet_name,df,excel_error_log_name):\n",
    "#-----------------------------------------------------------------------------------\n",
    "#Boncodes Uniqueness*: same boncode has been used only once in the dictionary file \n",
    "#Identify any duplicated Boncodes in across the dictionary\n",
    "#-----------------------------------------------------------------------------------\n",
    "#add items one by one to a list and while adding check if it is duplicated or not\n",
    "    firstsheet = excel_error_log_name['Intro']\n",
    "    try: \n",
    "        outputsheet = excel_error_log_name[sheet_name[5:] + ' Output']  # defining which sheet the output needs to go into\n",
    "        outputsheet['B10'].value = 'Data Validation Rule 8'\n",
    "        index=3 #index for showing row position\n",
    "        boncode_duplicates = []\n",
    "        error_counter=0\n",
    "        \n",
    "        for item in df['Reference']:  \n",
    "            index += 1\n",
    "            if item in boncode_duplicates:\n",
    "                error_counter += 1\n",
    "                outputsheet['C10'].value = f\"Error in row {index}: Reference: {item} is not unique\"\n",
    "                outputsheet['C10'].fill = red_fill\n",
    "            else: \n",
    "                boncode_duplicates.append(item)\n",
    "        if error_counter == 0:\n",
    "            outputsheet['C10'].value = \"Success, No Errors detected!\"\n",
    "            outputsheet['C10'].fill = green_fill\n",
    "    except ValueError:\n",
    "        firstsheet['B6'].value = f\"{firstsheet['B6'].value}{ValueError} \\n\"\n",
    "        firstsheet['B6'].fill = red_fill\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def user_text_input(sheet_name, df, excel_error_log_name):\n",
    "    # ---------------------------------------------------------------------\n",
    "    ##Whether the values (e.g. anything under the years headers) corresponds to what is in the units columns\n",
    "    # If the Unit value is not ‘Text’ the years columns values should be number\n",
    "    #sheet RR 414-419, 489-491 error because unit is weird\n",
    "    # ---------------------------------------------------------------------\n",
    "    regex_columns = r'^([0-9]{4}-[0-9]{2})$'\n",
    "    regex_pattern = re.compile(regex_columns)\n",
    "\n",
    "    firstsheet = excel_error_log_name['Intro']\n",
    "    try:\n",
    "        outputsheet = excel_error_log_name[sheet_name[5:] + ' Output']  # defining which sheet the output needs to go into\n",
    "        outputsheet['B8'].value = 'Data Validation Rule 6 (will not stop data loading to fountain)'\n",
    "        outputsheet['C8'].value = \"\"\n",
    "        index = 3\n",
    "        error_counter = 0\n",
    "\n",
    "        for i, row in df.iterrows():\n",
    "            index += 1\n",
    "            for key in row.keys():\n",
    "                if bool(regex_pattern.match(key)) or key.lower() == 'constant':\n",
    "                    if row[key] == \"##BLANK\":\n",
    "                        continue\n",
    "                    elif row[key] == True:\n",
    "                        continue\n",
    "                    elif row[key] == False:\n",
    "                        continue\n",
    "                    elif row[key] == \"#REF!\": \n",
    "                        continue\n",
    "                    elif (row[\"Unit\"] == \"Time\"):\n",
    "                        continue\n",
    "                    elif row[key] == \"#DIV/0!\":\n",
    "                        continue\n",
    "                    elif pd.isna(row[key]):\n",
    "                        continue\n",
    "                    elif row[key] == '\\xa0':\n",
    "                        continue\n",
    "                    elif row[key] == int(0) or row[key] == float(0) or row[key] == str(0):\n",
    "                        continue\n",
    "                    elif pd.isna(row[\"Unit\"]):\n",
    "                        continue\n",
    "                    # if unit is text and value in every column is not string\n",
    "                    elif (row[\"Unit\"].lower() in [\"text\"]) and type(row[key]) != str:\n",
    "                        error_counter += 1\n",
    "                        outputsheet['C8'].value = f\"{outputsheet['C8'].value} Error in Row: {index}, Reference: {df.loc[i, 'Reference']}, Column: {key}, Value: {row[key]}, \" \\\n",
    "                            \"This is a text field, please check that your input is in text format \\n\"\n",
    "                        outputsheet['C8'].fill = red_fill\n",
    "        if error_counter == 0:\n",
    "            outputsheet['C8'].value = \"Success, No Errors detected!\"\n",
    "            outputsheet['C8'].fill = green_fill \n",
    "    except ValueError:\n",
    "        firstsheet['B6'].value = f\"{firstsheet['B6'].value} {ValueError} \\n\"\n",
    "        firstsheet['B6'].fill = red_fill\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def boncode_Consistency(sheet_name,dict_of_sheets,original_dict_of_sheets,excel_error_log_name):\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "#Boncode Consistency*, prevent accidental change/delete of Boncodes\n",
    "#-----------------------------------------------------------------------------------\n",
    "    firstsheet = excel_error_log_name['Intro']\n",
    "    try:\n",
    "        outputsheet = excel_error_log_name[sheet_name[5:] + ' Output']  # defining which sheet the output needs to go into\n",
    "        outputsheet['B9'].value = 'Data Validation Rule 7'\n",
    "        outputsheet['C9'].value = \"\"\n",
    "        amended_boncodes=dict_of_sheets['Reference']\n",
    "        original_boncodes=original_dict_of_sheets['Reference']\n",
    "        result_string = ''\n",
    "        original_only_boncodes = list(set(original_boncodes) - set(amended_boncodes))  # The items in the original version, but not in ammended version\n",
    "        for item in original_only_boncodes:\n",
    "            if item !=np.nan and item != 'nan':\n",
    "                result_string += str(item) + '\\n'\n",
    "        if len(original_only_boncodes) > 0:\n",
    "            outputsheet['C9'].value = f\"{outputsheet['C9'].value} Reference (Boncodes) in worksheet in the original version but not in the amended version: {result_string}\"\n",
    "            outputsheet['C9'].fill = red_fill\n",
    "        else:\n",
    "            outputsheet['C9'].value = \"Success, No Errors detected!\"\n",
    "            outputsheet['C9'].fill = green_fill\n",
    "    except ValueError:\n",
    "        firstsheet['B6'].value = f\"{firstsheet['B6'].value} {ValueError} \\n\"\n",
    "        firstsheet['B6'].fill = red_fill\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_numerical_input(sheet_name, df, excel_error_log_name):\n",
    "    # ---------------------------------------------------------------------\n",
    "    ##Whether the values (e.g. anything under the years headers) corresponds to what is in the units columns\n",
    "    # If the Unit value is not ‘Text’ the years columns values should be number\n",
    "    #sheet RR 414-419, 489-491 error because unit is weird\n",
    "    # ---------------------------------------------------------------------\n",
    "    unit_list = [ '£','000','days','hours','kg','km','kw','l/', 'litres','m2','m3','mg','minutes','ml','months','mtrs','num','tonnes','year','ttds']\n",
    "\n",
    "    regex_columns = r'^([0-9]{4}-[0-9]{2})$'\n",
    "    regex_pattern = re.compile(regex_columns)\n",
    "\n",
    "    firstsheet = excel_error_log_name['Intro']\n",
    "    try:\n",
    "        outputsheet = excel_error_log_name[sheet_name[5:] + ' Output']  # defining which sheet the output needs to go into\n",
    "        outputsheet['B11'].value = 'Data Validation Rule 9'\n",
    "        outputsheet['C11'].value = \"\"\n",
    "\n",
    "        index = 3  # index for showing row position\n",
    "        error_counter = 0\n",
    "\n",
    "        for i, row in df.iterrows():\n",
    "            index += 1\n",
    "            for key in row.keys():\n",
    "                if bool(regex_pattern.match(key)) or key.lower() == 'constant':\n",
    "                    if row[key] == True:\n",
    "                        continue\n",
    "                    elif row[key] == False: \n",
    "                        continue\n",
    "                    elif row[key] == \"##BLANK\":\n",
    "                        continue\n",
    "                    elif row[key] == \"#DIV/0!\":\n",
    "                        continue\n",
    "                    elif row[key] == \"#REF!\": \n",
    "                        continue\n",
    "                    elif pd.isna(row[key]):\n",
    "                        continue\n",
    "                    elif row[key] == '\\xa0':\n",
    "                        continue\n",
    "                    elif row[key] == int(0) or row[key] == float(0) or row[key] == str(0):\n",
    "                        continue\n",
    "                    elif pd.isna(row[\"Unit\"]):\n",
    "                        continue\n",
    "                    elif (row[\"Unit\"] == \"Time\"):\n",
    "                        continue\n",
    "                    # if unit is numeric, look at the list and value in every column is not int or float\n",
    "                    else: \n",
    "                        for substring in unit_list:\n",
    "                            if substring in str(row[\"Unit\"]).lower():\n",
    "                                if isinstance(row[key], str) and row[key].replace('.', '').isdigit():\n",
    "                                    continue\n",
    "                                elif type(row[key]) != int and type(row[key]) != float:\n",
    "                                    #print(f\"type: {type(row[key])}, value: {row[key]}, bon: {row['Reference']}, year: {key}  \")\n",
    "                                    error_counter += 1\n",
    "                                    outputsheet['C11'].value = f\"{outputsheet['C11'].value} Error in Row: {index}, Reference: {df.loc[i, 'Reference']}, Column: {key}, Value: {row[key]}, \" \\\n",
    "                                        \"This is a numeric field, please check that your input is in numerical format. \\n\"\n",
    "                                    outputsheet['C11'].fill = red_fill\n",
    "        if error_counter == 0:\n",
    "            outputsheet['C11'].value = \"Success, No Errors detected!\"\n",
    "            outputsheet['C11'].fill = green_fill\n",
    "    except ValueError:\n",
    "        firstsheet['B6'].value = f\"{firstsheet['B6'].value} {ValueError} \\n\"\n",
    "        firstsheet['B6'].fill = red_fill\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_range(sheet_name, df, excel_error_log_name):\n",
    "    #checks that entries where the unit is a percentage fall between 0 and 100\n",
    "    regex_columns = r'^([0-9]{4}-[0-9]{2})$'\n",
    "    regex_pattern = re.compile(regex_columns)\n",
    "\n",
    "    firstsheet = excel_error_log_name['Intro']\n",
    "    try:\n",
    "        outputsheet = excel_error_log_name[sheet_name[5:] + ' Output']  # defining which sheet the output needs to go into\n",
    "        outputsheet['B12'].value = 'Data Validation Rule 10 (will not stop data loading to fountain)'\n",
    "        outputsheet['C12'].value = \"\"\n",
    "\n",
    "        index = 3  # index for showing row position\n",
    "        error_counter = 0\n",
    "\n",
    "        for i, row in df.iterrows():\n",
    "            index += 1\n",
    "            for key in row.keys():\n",
    "                if bool(regex_pattern.match(key)) or key.lower() == 'constant':\n",
    "                    if (row[\"Unit\"] == \"%\"):\n",
    "                        if type(row[key]) == int or type(row[key]) == float:\n",
    "                            if row[key]<-2 or row[key]>2:\n",
    "                                error_counter += 1\n",
    "                                outputsheet['C12'].value = f\"{outputsheet['C12'].value} Error in Row: {index}, Reference: {df.loc[i, 'Reference']}, Column: {key}, Value: {row[key]}, \" \\\n",
    "                                    \"This is a percentage outside the expected range, with absolute value less than 2, please check that this value is correct. \\n\"\n",
    "                                outputsheet['C12'].fill = red_fill        \n",
    "        if error_counter == 0:\n",
    "            outputsheet['C12'].value = \"Success, No Errors detected!\"\n",
    "            outputsheet['C12'].fill = green_fill\n",
    "    except ValueError:\n",
    "        firstsheet['B6'].value = f\"{firstsheet['B6'].value} {ValueError} \\n\"\n",
    "        firstsheet['B6'].fill = red_fill\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] The directory name is invalid: 'C:\\\\Users\\\\Nahila.Chowdhury\\\\OneDrive - OFWAT\\\\Data\\\\Business Plan Tables\\\\August 2024 BPT Submission\\\\3_Files error fixing WORKING\\\\Additional Tables\\\\UUWR_91_Additional data tables_DT1.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:6\u001b[0m\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m: [WinError 267] The directory name is invalid: 'C:\\\\Users\\\\Nahila.Chowdhury\\\\OneDrive - OFWAT\\\\Data\\\\Business Plan Tables\\\\August 2024 BPT Submission\\\\3_Files error fixing WORKING\\\\Additional Tables\\\\UUWR_91_Additional data tables_DT1.xlsx'"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "original_file_location = v7_bpt\n",
    "\n",
    "path = input_files\n",
    "\n",
    "# Change the directory to the O drive\n",
    "os.chdir(path)\n",
    "\n",
    "#for file in glob.glob(\"PR24 Data Tables 240314 variant plan DAM_Amended.xlsx\"):  # glob is a way of getting all the files of a certain type\n",
    "for file in glob.glob(r\"*.xlsx\"):  # glob is a way of getting all the files of a certain type\n",
    "    acronym = file[0:3]\n",
    "    file_location = file\n",
    "    \n",
    "    workbook = openpyxl.Workbook()  # creating a new excel sheet to store the data\n",
    "    sheet = workbook.active  # calling the first sheet\n",
    "    sheet.title = \"Intro\"  # defining the first sheet to give the user an introduction\n",
    "    intro = workbook[\"Intro\"]\n",
    "    intro['B2'].value = 'This is the introduction sheet, each sheet after this will detail the outputs. This version of Proteus runs against V7 BPT.'\n",
    "    intro['B8'].value = 'NOTE that we should be expecting to see Boncode errors containing XXX in the OUT and LS_MAN sheets, if you do not see this, make a note in the error log to edit the company specific bons.'\n",
    "     \n",
    "    dict_of_sheets={}\n",
    "    dict_of_sheets=import_data(file_location,workbook)\n",
    "    original_dict_of_sheets={}\n",
    "    original_dict_of_sheets=import_original_data(original_file_location,workbook)\n",
    "    main(dict_of_sheets,original_dict_of_sheets,workbook)\n",
    "    timestamp_error_log(workbook)\n",
    "    \n",
    "    excel_error_log_name = (error_output_path + acronym + \" Excel Error log_\" + datetime.datetime.now().strftime(\"%d.%m.%Y %H.%M\") + \".xlsx\")\n",
    "    workbook.save(excel_error_log_name)\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### END OF FUNCTIONS RUN FOR FOUTPUTS "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
